{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Spam detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from scipy.stats import randint, uniform\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the dataset\n",
    "df = pd.read_csv(r\"D:\\projects\\Spam_Ham\\Dataset\\spam_dataset.csv\", encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>v1</th>\n",
       "      <th>v2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     v1                                                 v2\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping unnecessary columns\n",
    "df.drop(columns=['Unnamed: 2', 'Unnamed: 3', 'Unnamed: 4'], inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   v1      5572 non-null   object\n",
      " 1   v2      5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n"
     ]
    }
   ],
   "source": [
    "# Checking dataset information\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replacing 'ham' and 'spam' labels with binary values (0 and 1)\n",
    "df.replace(to_replace={'ham': 0, 'spam': 1}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    4825\n",
       "1     747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of 'ham' and 'spam' in the dataset\n",
    "df['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "v1\n",
       "0    747\n",
       "1    747\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "\n",
    "# Separate majority and minority classes\n",
    "df_majority = df[df['v1'] == 0]\n",
    "df_minority = df[df['v1'] == 1]\n",
    "\n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=len(df_minority),  # match minority class\n",
    "                                   random_state=42)  # reproducible results\n",
    "\n",
    "# Combine minority class with downsampled majority class\n",
    "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
    "\n",
    "# Display new class counts\n",
    "df_downsampled['v1'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into features (X) and labels (y)\n",
    "X,y = df_downsampled.iloc[:,1],df_downsampled.iloc[:,0].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the TF-IDF Vectorizer\n",
    "Vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Transforming the text data to TF-IDF features\n",
    "Transformed_X = Vectorizer.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(Transformed_X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing machine learning models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining parameter distributions for RandomizedSearchCV\n",
    "param_dists = {\n",
    "    'Logistic Regression': {\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'C':  [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "        'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n",
    "        'max_iter': [100, 200, 500]\n",
    "        \n",
    "    },\n",
    "    'Random Forest': {\n",
    "        'n_estimators': [50,100,150,175,200,250,300,400,450],\n",
    "        'max_depth': [None] + list(range(5, 50)),\n",
    "        'min_samples_split': [2,4,5,7,8,10,15,20],\n",
    "        'min_samples_leaf': [1,2,4,5,7,8,10,15,20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    },\n",
    "    'Decision Tree': {\n",
    "        'max_depth': [None] + list(range(5, 50)),\n",
    "        'min_samples_split': [2,4,5,7,8,10,15,20],\n",
    "        'min_samples_leaf': [1,2,4,5,7,8,10,15,20],\n",
    "        'criterion': ['gini', 'entropy'],\n",
    "    },\n",
    "    'SVC': {\n",
    "        'C': [0.1,2,3,4,5,6,8,10],\n",
    "        'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "        'gamma': ['scale', 'auto'] ,\n",
    "        'degree': [2,3,4,5,6,7,8,9,10],\n",
    "    },\n",
    "    'Multinomial Naive Bayes': {\n",
    "        'alpha': [1e-10,1e-5,1e-3,0.01,.1],\n",
    "        'fit_prior': [True, False],\n",
    "    }\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate models\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'SVC': SVC(),\n",
    "    'Multinomial Naive Bayes': MultinomialNB()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dictionary to store the trained models\n",
    "Trained_model = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning hyperparameters for Logistic Regression...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters for Logistic Regression: {'solver': 'saga', 'penalty': 'l2', 'max_iter': 200, 'C': 100}\n",
      "Best score for Logistic Regression: 0.9553626471305071\n",
      "\n",
      "Tuning hyperparameters for Random Forest...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters for Random Forest: {'n_estimators': 100, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_depth': 45, 'criterion': 'entropy'}\n",
      "Best score for Random Forest: 0.9508895929807458\n",
      "\n",
      "Tuning hyperparameters for Decision Tree...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters for Decision Tree: {'min_samples_split': 5, 'min_samples_leaf': 1, 'max_depth': 19, 'criterion': 'gini'}\n",
      "Best score for Decision Tree: 0.9232054020730885\n",
      "\n",
      "Tuning hyperparameters for SVC...\n",
      "Fitting 3 folds for each of 50 candidates, totalling 150 fits\n",
      "Best parameters for SVC: {'kernel': 'sigmoid', 'gamma': 'scale', 'degree': 4, 'C': 3}\n",
      "Best score for SVC: 0.9535848948402172\n",
      "\n",
      "Tuning hyperparameters for Multinomial Naive Bayes...\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n",
      "Best parameters for Multinomial Naive Bayes: {'fit_prior': True, 'alpha': 0.1}\n",
      "Best score for Multinomial Naive Bayes: 0.9562491338236488\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Tuning hyperparameters and training the models\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Tuning hyperparameters for {model_name}...\")\n",
    "    random_search = RandomizedSearchCV(model, param_dists[model_name], n_iter=50, cv=3, verbose=2, random_state=42, n_jobs=-1)\n",
    "    random_search.fit(X_train,y_train)\n",
    "    Trained_model[model_name] = random_search.best_estimator_\n",
    "    print(f\"Best parameters for {model_name}: {random_search.best_params_}\")\n",
    "    print(f\"Best score for {model_name}: {random_search.best_score_}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing metrics for evaluation\n",
    "from sklearn.metrics import accuracy_score,precision_score,confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression\n",
      "The accuaracy of the Logistic Regression model is 0.9572192513368984\n",
      "The precision of the Logistic Regression model is 0.9763313609467456\n",
      "[[193   4]\n",
      " [ 12 165]]\n",
      "\n",
      "Random Forest\n",
      "The accuaracy of the Random Forest model is 0.9518716577540107\n",
      "The precision of the Random Forest model is 0.9818181818181818\n",
      "[[194   3]\n",
      " [ 15 162]]\n",
      "\n",
      "Decision Tree\n",
      "The accuaracy of the Decision Tree model is 0.8796791443850267\n",
      "The precision of the Decision Tree model is 0.8586956521739131\n",
      "[[171  26]\n",
      " [ 19 158]]\n",
      "\n",
      "SVC\n",
      "The accuaracy of the SVC model is 0.946524064171123\n",
      "The precision of the SVC model is 0.9700598802395209\n",
      "[[192   5]\n",
      " [ 15 162]]\n",
      "\n",
      "Multinomial Naive Bayes\n",
      "The accuaracy of the Multinomial Naive Bayes model is 0.9652406417112299\n",
      "The precision of the Multinomial Naive Bayes model is 0.9767441860465116\n",
      "[[193   4]\n",
      " [  9 168]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluating the models on the test set\n",
    "for model_name, model in Trained_model.items():\n",
    "    \n",
    "    y_pred = model.predict(X_test)\n",
    "    print(model_name)\n",
    "    print(f\"The accuaracy of the {model_name} model is {accuracy_score(y_test,y_pred)}\")\n",
    "    print(f\"The precision of the {model_name} model is {precision_score(y_test,y_pred)}\")\n",
    "    print(confusion_matrix(y_test,y_pred))\n",
    "    print()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Based on the performance, Multinomial Naive Bayes is selected as the final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing joblib for saving the model\n",
    "from joblib import load,dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting the best model (Multinomial Naive Bayes)\n",
    "model = Trained_model['Multinomial Naive Bayes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Spam_Model.joblib']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the final model to a file\n",
    "dump(model,'Spam_Model.joblib')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Vectorizer.joblib']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the Vectorizer\n",
    "\n",
    "dump(Vectorizer,'Vectorizer.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
